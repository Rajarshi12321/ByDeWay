{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /root/Depth-SoM/Depth-Anything-V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xFormers not available\n",
      "xFormers not available\n",
      "2025-03-10 12:12:23.302236: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 12:12:23.313529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741608743.332963    1052 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741608743.338277    1052 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 12:12:23.356344: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from depth_kosmos import requests, DepthKosmosCaptioner\n",
    "from depth_kosmos import Image as Image_PIL\n",
    "\n",
    "depth_kosmos_captioner = DepthKosmosCaptioner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTp5jMLHnfiO56w8iVWAwI4VvOu4B_5c2C1ww&s\"\n",
    "image = Image_PIL.open(requests.get(url, stream=True).raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded as NumPy array:\n",
      "(183, 275, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest: a woman carrying a basket of plants\n",
      "----\n",
      "Mid Range: a soldier\n",
      "----\n",
      "Farthest: a woman\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# depth_kosmos_captioner.display_depth_images(image)\n",
    "full_caption_string = depth_kosmos_captioner.get_caption_with_depth(image)\n",
    "print(full_caption_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9022e4a0234b75a222e9a8ea74b029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bfdce3b3d24baea8435d821ca68213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/15.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8689959d4534603994177834c574bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/148 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: image/image_0.jpg\n",
      "✅ Saved: image/image_1.jpg\n",
      "✅ Saved: image/image_2.jpg\n",
      "✅ Saved: image/image_3.jpg\n",
      "✅ Saved: image/image_4.jpg\n",
      "✅ Saved: image/image_5.jpg\n",
      "✅ Saved: image/image_6.jpg\n",
      "✅ Saved: image/image_7.jpg\n",
      "✅ Saved: image/image_8.jpg\n",
      "✅ Saved: image/image_9.jpg\n",
      "✅ Saved: image/image_10.jpg\n",
      "✅ Saved: image/image_11.jpg\n",
      "✅ Saved: image/image_12.jpg\n",
      "✅ Saved: image/image_13.jpg\n",
      "✅ Saved: image/image_14.jpg\n",
      "✅ Saved: image/image_15.jpg\n",
      "✅ Saved: image/image_16.jpg\n",
      "✅ Saved: image/image_17.jpg\n",
      "✅ Saved: image/image_18.jpg\n",
      "✅ Saved: image/image_19.jpg\n",
      "✅ Saved: image/image_20.jpg\n",
      "✅ Saved: image/image_21.jpg\n",
      "✅ Saved: image/image_22.jpg\n",
      "✅ Saved: image/image_23.jpg\n",
      "✅ Saved: image/image_24.jpg\n",
      "✅ Saved: image/image_25.jpg\n",
      "✅ Saved: image/image_26.jpg\n",
      "✅ Saved: image/image_27.jpg\n",
      "✅ Saved: image/image_28.jpg\n",
      "✅ Saved: image/image_29.jpg\n",
      "✅ Saved: image/image_30.jpg\n",
      "✅ Saved: image/image_31.jpg\n",
      "✅ Saved: image/image_32.jpg\n",
      "✅ Saved: image/image_33.jpg\n",
      "✅ Saved: image/image_34.jpg\n",
      "✅ Saved: image/image_35.jpg\n",
      "✅ Saved: image/image_36.jpg\n",
      "✅ Saved: image/image_37.jpg\n",
      "✅ Saved: image/image_38.jpg\n",
      "✅ Saved: image/image_39.jpg\n",
      "✅ Saved: image/image_40.jpg\n",
      "✅ Saved: image/image_41.jpg\n",
      "✅ Saved: image/image_42.jpg\n",
      "✅ Saved: image/image_43.jpg\n",
      "✅ Saved: image/image_44.jpg\n",
      "✅ Saved: image/image_45.jpg\n",
      "✅ Saved: image/image_46.jpg\n",
      "✅ Saved: image/image_47.jpg\n",
      "✅ Saved: image/image_48.jpg\n",
      "✅ Saved: image/image_49.jpg\n",
      "✅ Saved: image/image_50.jpg\n",
      "✅ Saved: image/image_51.jpg\n",
      "✅ Saved: image/image_52.jpg\n",
      "✅ Saved: image/image_53.jpg\n",
      "✅ Saved: image/image_54.jpg\n",
      "✅ Saved: image/image_55.jpg\n",
      "✅ Saved: image/image_56.jpg\n",
      "✅ Saved: image/image_57.jpg\n",
      "✅ Saved: image/image_58.jpg\n",
      "✅ Saved: image/image_59.jpg\n",
      "✅ Saved: image/image_60.jpg\n",
      "✅ Saved: image/image_61.jpg\n",
      "✅ Saved: image/image_62.jpg\n",
      "✅ Saved: image/image_63.jpg\n",
      "✅ Saved: image/image_64.jpg\n",
      "✅ Saved: image/image_65.jpg\n",
      "✅ Saved: image/image_66.jpg\n",
      "✅ Saved: image/image_67.jpg\n",
      "✅ Saved: image/image_68.jpg\n",
      "✅ Saved: image/image_69.jpg\n",
      "✅ Saved: image/image_70.jpg\n",
      "✅ Saved: image/image_71.jpg\n",
      "✅ Saved: image/image_72.jpg\n",
      "✅ Saved: image/image_73.jpg\n",
      "✅ Saved: image/image_74.jpg\n",
      "✅ Saved: image/image_75.jpg\n",
      "✅ Saved: image/image_76.jpg\n",
      "✅ Saved: image/image_77.jpg\n",
      "✅ Saved: image/image_78.jpg\n",
      "✅ Saved: image/image_79.jpg\n",
      "✅ Saved: image/image_80.jpg\n",
      "✅ Saved: image/image_81.jpg\n",
      "✅ Saved: image/image_82.jpg\n",
      "✅ Saved: image/image_83.jpg\n",
      "✅ Saved: image/image_84.jpg\n",
      "✅ Saved: image/image_85.jpg\n",
      "✅ Saved: image/image_86.jpg\n",
      "✅ Saved: image/image_87.jpg\n",
      "✅ Saved: image/image_88.jpg\n",
      "✅ Saved: image/image_89.jpg\n",
      "✅ Saved: image/image_90.jpg\n",
      "✅ Saved: image/image_91.jpg\n",
      "✅ Saved: image/image_92.jpg\n",
      "✅ Saved: image/image_93.jpg\n",
      "✅ Saved: image/image_94.jpg\n",
      "✅ Saved: image/image_95.jpg\n",
      "✅ Saved: image/image_96.jpg\n",
      "✅ Saved: image/image_97.jpg\n",
      "✅ Saved: image/image_98.jpg\n",
      "✅ Saved: image/image_99.jpg\n",
      "✅ Saved: image/image_100.jpg\n",
      "✅ Saved: image/image_101.jpg\n",
      "✅ Saved: image/image_102.jpg\n",
      "✅ Saved: image/image_103.jpg\n",
      "✅ Saved: image/image_104.jpg\n",
      "✅ Saved: image/image_105.jpg\n",
      "✅ Saved: image/image_106.jpg\n",
      "✅ Saved: image/image_107.jpg\n",
      "✅ Saved: image/image_108.jpg\n",
      "✅ Saved: image/image_109.jpg\n",
      "✅ Saved: image/image_110.jpg\n",
      "✅ Saved: image/image_111.jpg\n",
      "✅ Saved: image/image_112.jpg\n",
      "✅ Saved: image/image_113.jpg\n",
      "✅ Saved: image/image_114.jpg\n",
      "✅ Saved: image/image_115.jpg\n",
      "✅ Saved: image/image_116.jpg\n",
      "✅ Saved: image/image_117.jpg\n",
      "✅ Saved: image/image_118.jpg\n",
      "✅ Saved: image/image_119.jpg\n",
      "✅ Saved: image/image_120.jpg\n",
      "✅ Saved: image/image_121.jpg\n",
      "✅ Saved: image/image_122.jpg\n",
      "✅ Saved: image/image_123.jpg\n",
      "✅ Saved: image/image_124.jpg\n",
      "✅ Saved: image/image_125.jpg\n",
      "✅ Saved: image/image_126.jpg\n",
      "✅ Saved: image/image_127.jpg\n",
      "✅ Saved: image/image_128.jpg\n",
      "✅ Saved: image/image_129.jpg\n",
      "✅ Saved: image/image_130.jpg\n",
      "✅ Saved: image/image_131.jpg\n",
      "✅ Saved: image/image_132.jpg\n",
      "✅ Saved: image/image_133.jpg\n",
      "✅ Saved: image/image_134.jpg\n",
      "✅ Saved: image/image_135.jpg\n",
      "✅ Saved: image/image_136.jpg\n",
      "✅ Saved: image/image_137.jpg\n",
      "✅ Saved: image/image_138.jpg\n",
      "✅ Saved: image/image_139.jpg\n",
      "✅ Saved: image/image_140.jpg\n",
      "✅ Saved: image/image_141.jpg\n",
      "✅ Saved: image/image_142.jpg\n",
      "✅ Saved: image/image_143.jpg\n",
      "✅ Saved: image/image_144.jpg\n",
      "✅ Saved: image/image_145.jpg\n",
      "✅ Saved: image/image_146.jpg\n",
      "✅ Saved: image/image_147.jpg\n",
      "✅ Updated DataFrame saved as 'updated_dataset.csv'!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 148/148 [03:47<00:00,  1.54s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f506e8e8204d2b82128f626754a4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9559a537dfb94316872ae76fc54c3dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/148 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df40207d9847498185b953af08ddf2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset successfully uploaded: Rajarshi-Roy-research/COCO_OVSEG_Som\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image</th>\n",
       "      <th>depth_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000023751_0</td>\n",
       "      <td>image/image_0.jpg</td>\n",
       "      <td>Closest: a person flying a kite\\n----\\nMid Ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000028452_0</td>\n",
       "      <td>image/image_1.jpg</td>\n",
       "      <td>Closest: a pink shelf\\n----\\nMid Range: a pink...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000013774_0</td>\n",
       "      <td>image/image_2.jpg</td>\n",
       "      <td>Closest: a person in a red suit\\n----\\nMid Ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000018737_0</td>\n",
       "      <td>image/image_3.jpg</td>\n",
       "      <td>Closest: a pink camel\\n----\\nMid Range: a red ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000001000_15</td>\n",
       "      <td>image/image_4.jpg</td>\n",
       "      <td>Closest: a group of people\\n----\\nMid Range: t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>000000006471_5</td>\n",
       "      <td>image/image_143.jpg</td>\n",
       "      <td>Closest: a baseball player\\n----\\nMid Range: a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>000000013201_5</td>\n",
       "      <td>image/image_144.jpg</td>\n",
       "      <td>Closest: a skateboarder in mid-air\\n----\\nMid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>000000001818_0</td>\n",
       "      <td>image/image_145.jpg</td>\n",
       "      <td>Closest: a pink and black striped fabric\\n----...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>000000002299_0</td>\n",
       "      <td>image/image_146.jpg</td>\n",
       "      <td>Closest: children\\n----\\nMid Range: a man\\n---...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>000000002592_0</td>\n",
       "      <td>image/image_147.jpg</td>\n",
       "      <td>Closest: a cup\\n----\\nMid Range: a purple teap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                image  \\\n",
       "0     000000023751_0    image/image_0.jpg   \n",
       "1     000000028452_0    image/image_1.jpg   \n",
       "2     000000013774_0    image/image_2.jpg   \n",
       "3     000000018737_0    image/image_3.jpg   \n",
       "4    000000001000_15    image/image_4.jpg   \n",
       "..               ...                  ...   \n",
       "143   000000006471_5  image/image_143.jpg   \n",
       "144   000000013201_5  image/image_144.jpg   \n",
       "145   000000001818_0  image/image_145.jpg   \n",
       "146   000000002299_0  image/image_146.jpg   \n",
       "147   000000002592_0  image/image_147.jpg   \n",
       "\n",
       "                                         depth_caption  \n",
       "0    Closest: a person flying a kite\\n----\\nMid Ran...  \n",
       "1    Closest: a pink shelf\\n----\\nMid Range: a pink...  \n",
       "2    Closest: a person in a red suit\\n----\\nMid Ran...  \n",
       "3    Closest: a pink camel\\n----\\nMid Range: a red ...  \n",
       "4    Closest: a group of people\\n----\\nMid Range: t...  \n",
       "..                                                 ...  \n",
       "143  Closest: a baseball player\\n----\\nMid Range: a...  \n",
       "144  Closest: a skateboarder in mid-air\\n----\\nMid ...  \n",
       "145  Closest: a pink and black striped fabric\\n----...  \n",
       "146  Closest: children\\n----\\nMid Range: a man\\n---...  \n",
       "147  Closest: a cup\\n----\\nMid Range: a purple teap...  \n",
       "\n",
       "[148 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "from PIL import Image as Image_PIL\n",
    "import shutil\n",
    "from datasets import load_dataset, Dataset, Image\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "hf_user = \"Rajarshi-Roy-research\"\n",
    "# dataset_name = \"Flickr30k_Grounding_Som\"\n",
    "# commit_message = \"Updating dataset with image paths\"\n",
    "# img_cols = [\"image\",\"wbox_image\"]\n",
    "# image_to_process = \"image\"\n",
    "\n",
    "dataset_name = \"COCO_OVSEG_Som\"\n",
    "commit_message = \"Updating dataset with images\"\n",
    "img_cols = [\"image\"]\n",
    "image_to_process = \"image\"\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def save_image_from_bytes(image_data, idx, image_folder):\n",
    "    \"\"\"Saves an image from byte data and returns the saved file path.\"\"\"\n",
    "    try:\n",
    "        image_bytes = image_data.get(\"bytes\", None)\n",
    "        if image_bytes:\n",
    "            image = Image_PIL.open(io.BytesIO(image_bytes))\n",
    "            image_path = os.path.join(image_folder, f\"image_{idx}.jpg\")\n",
    "            image.save(image_path, format=\"JPEG\")\n",
    "            print(f\"✅ Saved: {image_path}\")\n",
    "            return image_path\n",
    "        else:\n",
    "            print(f\"⚠️ Skipped row {idx}: No bytes found\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving image at row {idx}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_image_from_df(df, depth_kosmos_captioner, image_folder):\n",
    "    \"\"\"Processes the DataFrame, adding depth captions and saving progress.\"\"\"\n",
    "    if \"depth_caption\" not in df.columns:\n",
    "        df[\"depth_caption\"] = None\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        if row[\"depth_caption\"] is None:\n",
    "            try:\n",
    "                if isinstance(row[\"image\"], dict): #Handle case where image is still a dict\n",
    "                    image_path = save_image_from_bytes(row[\"image\"], index, image_folder)\n",
    "                    if image_path:\n",
    "                        image = Image_PIL.open(image_path)\n",
    "                        full_caption_string = depth_kosmos_captioner.get_caption_with_depth(image)\n",
    "                        df.loc[index, \"depth_caption\"] = full_caption_string\n",
    "                elif isinstance(row[\"image\"], str): #Handle case where image is a file path\n",
    "                    image = Image_PIL.open(row[\"image\"])\n",
    "                    full_caption_string = depth_kosmos_captioner.get_caption_with_depth(image)\n",
    "                    df.loc[index, \"depth_caption\"] = full_caption_string\n",
    "                else:\n",
    "                    print(f\"⚠️ Unexpected image type at index {index}: {type(row['image'])}\")\n",
    "                    df.loc[index, \"depth_caption\"] = \"Error: Unexpected image type\"\n",
    "\n",
    "                df.to_parquet(\"df_with_captions.parquet\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image at index {index}: {e}\")\n",
    "                df.loc[index, \"depth_caption\"] = \"Error\"\n",
    "                df.to_parquet(\"df_with_captions.parquet\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def push_df_to_hugging_face(df, img_cols, hf_user, dataset_name, commit_message, hf_token, private=False):\n",
    "    \"\"\"Pushes the DataFrame to the Hugging Face Hub.\"\"\"\n",
    "    hf_dataset = Dataset.from_pandas(df)\n",
    "    \n",
    "    for img_col in img_cols:\n",
    "        hf_dataset = hf_dataset.cast_column(img_col, Image())\n",
    "\n",
    "    try:\n",
    "        hf_dataset.push_to_hub(\n",
    "            repo_id=f\"{hf_user}/{dataset_name}\",\n",
    "            commit_message=commit_message,\n",
    "            token=hf_token,\n",
    "            private=private,\n",
    "        )\n",
    "        print(f\"✅ Dataset successfully uploaded: {hf_user}/{dataset_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error pushing to Hugging Face Hub: {e}\")\n",
    "\n",
    "\n",
    "# --- Main Script ---\n",
    "# Clean up existing image folder\n",
    "for img_col in img_cols:\n",
    "    if os.path.exists(img_col):\n",
    "        shutil.rmtree(img_col)\n",
    "    os.makedirs(img_col)\n",
    "\n",
    "# Load dataset\n",
    "ds = load_dataset(f\"{hf_user}/{dataset_name}\")\n",
    "df = ds[\"train\"].to_pandas()\n",
    "\n",
    "for img_col in img_cols:\n",
    "    # Save images and update DataFrame\n",
    "    for i, row in df.iterrows():\n",
    "        if isinstance(row[img_col], dict):\n",
    "            df.at[i, img_col] = save_image_from_bytes(row[img_col], i, img_col)\n",
    "\n",
    "df.to_csv(\"updated_dataset.csv\", index=False)\n",
    "print(\"✅ Updated DataFrame saved as 'updated_dataset.csv'!\")\n",
    "\n",
    "#Process and add captions\n",
    "try:\n",
    "    df = pd.read_csv(\"updated_dataset.csv\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "df = process_image_from_df(df, depth_kosmos_captioner, image_to_process)\n",
    "\n",
    "# Authenticate and push to Hugging Face\n",
    "\n",
    "login(token=hf_token)\n",
    "push_df_to_hugging_face(df, img_cols, hf_user, dataset_name, commit_message, hf_token, private=True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
